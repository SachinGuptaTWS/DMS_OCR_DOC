{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "import csv\n",
        "import time\n",
        "import difflib\n",
        "import codecs\n",
        "\n",
        "# ==========================================\n",
        "# 1. INPUT HANDLING & UTILITIES\n",
        "# ==========================================\n",
        "def get_user_file():\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"[STEP 1] FILE UPLOAD SELECTION\")\n",
        "    print(\"=\"*50)\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        print(\"[INFO] Environment: Google Colab detected.\")\n",
        "        print(\"[ACTION] Please upload your .txt file now...\")\n",
        "        uploaded = files.upload()\n",
        "        if not uploaded:\n",
        "            return None\n",
        "        return list(uploaded.keys())[0]\n",
        "    except ImportError:\n",
        "        print(\"[INFO] Environment: Local Python detected.\")\n",
        "        filepath = input(\"[INPUT] Enter the full path to your .txt file: \").strip()\n",
        "        return filepath if os.path.exists(filepath) else None\n",
        "\n",
        "def read_file_safely(filepath):\n",
        "    \"\"\"\n",
        "    Attempts to read a file using multiple encodings to handle legacy/messy data.\n",
        "    Returns: content (str), encoding_used (str)\n",
        "    \"\"\"\n",
        "    encodings = ['utf-8', 'latin-1', 'cp1252', 'ascii']\n",
        "\n",
        "    for enc in encodings:\n",
        "        try:\n",
        "            with codecs.open(filepath, 'r', encoding=enc) as f:\n",
        "                return f.read(), enc\n",
        "        except UnicodeDecodeError:\n",
        "            continue\n",
        "\n",
        "    # Fallback: Ignore errors if all encodings fail\n",
        "    with open(filepath, 'r', errors='ignore') as f:\n",
        "        return f.read(), \"unknown (lossy)\"\n",
        "\n",
        "# ==========================================\n",
        "# 2. STRATEGY A: STRUCTURED DATA MINING\n",
        "# ==========================================\n",
        "def extract_structured_blocks(filepath):\n",
        "    \"\"\"\n",
        "    Scans for tabular data blocks using heuristic delimiter density analysis.\n",
        "    Supported Delimiters: Pipe (|), Comma (,), Tab (\\t), Semicolon (;)\n",
        "    \"\"\"\n",
        "    print(f\"\\n[INFO] Initiating structured data scan on: {filepath}...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    content, _ = read_file_safely(filepath)\n",
        "    lines = content.splitlines()\n",
        "\n",
        "    extracted_tables = []\n",
        "    current_block = []\n",
        "\n",
        "    # Heuristic: A line is \"structured\" if it contains a significant number of delimiters\n",
        "    def is_likely_table_row(line):\n",
        "        if len(line) > 1000: return False # Skip massive text dumps\n",
        "        # Check for common delimiters\n",
        "        if line.count('|') >= 2: return True\n",
        "        if line.count('\\t') >= 2: return True\n",
        "        if line.count(';') >= 2: return True\n",
        "        if line.count(',') >= 2: return True\n",
        "        return False\n",
        "\n",
        "    for line in lines:\n",
        "        stripped = line.strip()\n",
        "        if not stripped: continue\n",
        "\n",
        "        if is_likely_table_row(stripped):\n",
        "            current_block.append(stripped)\n",
        "        else:\n",
        "            if len(current_block) > 1:\n",
        "                parsed_data = parse_block(current_block)\n",
        "                if parsed_data:\n",
        "                    extracted_tables.append(parsed_data)\n",
        "                current_block = []\n",
        "\n",
        "    # Capture trailing block\n",
        "    if len(current_block) > 1:\n",
        "        parsed_data = parse_block(current_block)\n",
        "        if parsed_data:\n",
        "            extracted_tables.append(parsed_data)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    metrics = {\n",
        "        \"time\": end_time - start_time,\n",
        "        \"tables_found\": len(extracted_tables),\n",
        "        \"total_rows\": sum(len(t) for t in extracted_tables)\n",
        "    }\n",
        "\n",
        "    return extracted_tables, metrics\n",
        "\n",
        "def parse_block(block_lines):\n",
        "    \"\"\"Attempts to parse a block of text lines into a list of dictionaries.\"\"\"\n",
        "    try:\n",
        "        # Auto-detect delimiter from the first valid line\n",
        "        sample = \"\\n\".join(block_lines[:5])\n",
        "        dialect = csv.Sniffer().sniff(sample, delimiters='|,\\t;')\n",
        "\n",
        "        data = []\n",
        "        reader = csv.DictReader(block_lines, dialect=dialect)\n",
        "        for row in reader:\n",
        "            # Clean whitespace from keys and values\n",
        "            clean_row = {k.strip(): v.strip() for k, v in row.items() if k and v}\n",
        "            if clean_row:\n",
        "                data.append(clean_row)\n",
        "        return data\n",
        "    except csv.Error:\n",
        "        return []\n",
        "    except Exception:\n",
        "        return []\n",
        "\n",
        "# ==========================================\n",
        "# 3. STRATEGY B: ADVANCED REGEX EXTRACTION\n",
        "# ==========================================\n",
        "def extract_unstructured(filepath):\n",
        "    \"\"\"\n",
        "    Extracts entities using advanced Regex patterns optimized for messy data.\n",
        "    \"\"\"\n",
        "    print(f\"\\n[INFO] Running natural language entity extraction...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    content, encoding = read_file_safely(filepath)\n",
        "    print(f\"[INFO] File read successfully using encoding: {encoding}\")\n",
        "\n",
        "    # Professional-grade patterns\n",
        "    patterns = {\n",
        "        \"Emails\": r'(?:[a-z0-9!#$%&\\'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&\\'*+/=?^_`{|}~-]+)*|\"(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21\\x23-\\x5b\\x5d-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])*\")@(?:(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?|\\[(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?|[a-z0-9-]*[a-z0-9]:(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21-\\x5a\\x53-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])+)\\])',\n",
        "        \"URLs\": r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)',\n",
        "        \"IPv4 Addresses\": r'\\b(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\b',\n",
        "        \"IPv6 Addresses\": r'([0-9a-fA-F]{1,4}:){7,7}[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,7}:|([0-9a-fA-F]{1,4}:){1,6}:[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,5}(:[0-9a-fA-F]{1,4}){1,2}|([0-9a-fA-F]{1,4}:){1,4}(:[0-9a-fA-F]{1,4}){1,3}|([0-9a-fA-F]{1,4}:){1,3}(:[0-9a-fA-F]{1,4}){1,4}|([0-9a-fA-F]{1,4}:){1,2}(:[0-9a-fA-F]{1,4}){1,5}|[0-9a-fA-F]{1,4}:((:[0-9a-fA-F]{1,4}){1,6})|:((:[0-9a-fA-F]{1,4}){1,7}|:)|fe80:(:[0-9a-fA-F]{0,4}){0,4}%[0-9a-zA-Z]{1,}|::(ffff(:0{1,4}){0,1}:){0,1}((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])|([0-9a-fA-F]{1,4}:){1,4}:((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])',\n",
        "        \"Phone Numbers\": r'\\+?1?\\s*\\(?-*\\.*(\\d{3})\\)?\\.*-*\\s*(\\d{3})\\.*-*\\s*(\\d{4})',\n",
        "        \"Dates\": r'\\b(?:\\d{4}[-/]\\d{2}[-/]\\d{2})|(?:\\d{2}[-/]\\d{2}[-/]\\d{4})|(?:\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* \\d{1,2}(?:st|nd|rd|th)?(?:, \\d{4})?)\\b',\n",
        "        \"Currency\": r'\\$\\s?\\d+(?:,\\d{3})*(?:\\.\\d{2})?',\n",
        "        \"MAC Addresses\": r'([0-9A-Fa-f]{2}[:-]){5}([0-9A-Fa-f]{2})',\n",
        "        \"System Error Codes\": r'\\b[A-Z0-9]+-[0-9]{3,}\\b',\n",
        "        \"Key-Value Pairs\": r'^([a-zA-Z0-9_]+)\\s*[:=]\\s*(.+)$' # e.g. \"Status: Active\" or \"id=500\"\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "    match_count = 0\n",
        "\n",
        "    # Use re.IGNORECASE for broader matching\n",
        "    flags = re.IGNORECASE | re.MULTILINE\n",
        "\n",
        "    for key, pattern in patterns.items():\n",
        "        matches = list(set(re.findall(pattern, content, flags)))\n",
        "\n",
        "        # Filter out empty tuples for complex regex groups\n",
        "        cleaned_matches = []\n",
        "        for m in matches:\n",
        "            if isinstance(m, tuple):\n",
        "                # Join tuple groups or pick the longest non-empty string\n",
        "                valid_parts = [p for p in m if p]\n",
        "                if valid_parts:\n",
        "                    cleaned_matches.append(valid_parts[0])\n",
        "            else:\n",
        "                cleaned_matches.append(m)\n",
        "\n",
        "        if cleaned_matches:\n",
        "            results[key] = cleaned_matches\n",
        "            match_count += len(cleaned_matches)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    metrics = {\n",
        "        \"time\": end_time - start_time,\n",
        "        \"entities\": match_count\n",
        "    }\n",
        "    return results, metrics, content\n",
        "\n",
        "# ==========================================\n",
        "# 4. UTILS & MAIN EXECUTION\n",
        "# ==========================================\n",
        "def calculate_accuracy(extracted_text, ground_truth):\n",
        "    if not ground_truth: return \"N/A\"\n",
        "\n",
        "    # Normalize for comparison\n",
        "    clean_truth = \" \".join(ground_truth.split())\n",
        "    clean_text = \" \".join(extracted_text.split())\n",
        "\n",
        "    # Check for exact substring presence\n",
        "    if clean_truth in clean_text:\n",
        "        return \"100.00% (Exact Match Verified)\"\n",
        "    else:\n",
        "        # Fallback to similarity ratio\n",
        "        ratio = difflib.SequenceMatcher(None, clean_truth, clean_text).ratio()\n",
        "        return f\"{ratio * 100:.2f}% (Similarity Estimate)\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    target_file = get_user_file()\n",
        "\n",
        "    if target_file:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"[STEP 2] ACCURACY VERIFICATION (OPTIONAL)\")\n",
        "        print(\"=\"*50)\n",
        "        ground_truth = input(\"[INPUT] Paste a known snippet from the file to verify accuracy (Enter to skip): \").strip()\n",
        "\n",
        "        # Strategy 1: Tables\n",
        "        tables, t_metrics = extract_structured_blocks(target_file)\n",
        "\n",
        "        print(\"\\n\" + \"-\"*50)\n",
        "        print(f\"[REPORT] STRUCTURED DATA EXTRACTION\")\n",
        "        print(\"-\" * 50)\n",
        "        print(f\"Time Taken: {t_metrics['time']:.4f}s\")\n",
        "        print(f\"Tables Detected: {t_metrics['tables_found']}\")\n",
        "\n",
        "        if tables:\n",
        "            for i, table in enumerate(tables):\n",
        "                print(f\"\\n--- Table Block {i+1} Preview (First 2 Rows) ---\")\n",
        "                print(json.dumps(table[:2], indent=4))\n",
        "        else:\n",
        "            print(\"[INFO] No structured table blocks identified.\")\n",
        "\n",
        "        # Strategy 2: Entities\n",
        "        entities, e_metrics, raw_text = extract_unstructured(target_file)\n",
        "\n",
        "        print(\"\\n\" + \"-\"*50)\n",
        "        print(f\"[REPORT] ENTITY EXTRACTION\")\n",
        "        print(\"-\" * 50)\n",
        "        print(f\"Time Taken: {e_metrics['time']:.4f}s\")\n",
        "        print(f\"Entities Found: {e_metrics['entities']}\")\n",
        "\n",
        "        if entities:\n",
        "            print(json.dumps(entities, indent=4))\n",
        "\n",
        "        # Accuracy\n",
        "        acc = calculate_accuracy(raw_text, ground_truth)\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(f\"[FINAL VERDICT] Accuracy Assessment: {acc}\")\n",
        "        print(\"=\" * 50)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "[STEP 1] FILE UPLOAD SELECTION\n",
            "==================================================\n",
            "[INFO] Environment: Google Colab detected.\n",
            "[ACTION] Please upload your .txt file now...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3b6a7edd-484b-4e4b-9693-d7b8d6e7eb04\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3b6a7edd-484b-4e4b-9693-d7b8d6e7eb04\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test_data.txt to test_data (3).txt\n",
            "\n",
            "==================================================\n",
            "[STEP 2] ACCURACY VERIFICATION (OPTIONAL)\n",
            "==================================================\n",
            "[INPUT] Paste a known snippet from the file to verify accuracy (Enter to skip): Wire the outstanding balance of $3,250.50 to the external contractor account.\n",
            "\n",
            "[INFO] Initiating structured data scan on: test_data (3).txt...\n",
            "\n",
            "--------------------------------------------------\n",
            "[REPORT] STRUCTURED DATA EXTRACTION\n",
            "--------------------------------------------------\n",
            "Time Taken: 0.0032s\n",
            "Tables Detected: 2\n",
            "\n",
            "--- Table Block 1 Preview (First 2 Rows) ---\n",
            "[\n",
            "    {\n",
            "        \"ID\": \"1001\",\n",
            "        \"TIMESTAMP\": \"2025-01-15 08:30:00\",\n",
            "        \"SEVERITY\": \"INFO\",\n",
            "        \"USER_EMAIL\": \"admin.sys@gateway.org\",\n",
            "        \"COST_IMPACT\": \"$0.00\",\n",
            "        \"STATUS\": \"ACTIVE\"\n",
            "    },\n",
            "    {\n",
            "        \"ID\": \"1002\",\n",
            "        \"TIMESTAMP\": \"2025-01-15 08:45:12\",\n",
            "        \"SEVERITY\": \"WARN\",\n",
            "        \"USER_EMAIL\": \"j.doe_dev@startup.io\",\n",
            "        \"COST_IMPACT\": \"$150.50\",\n",
            "        \"STATUS\": \"REVIEW\"\n",
            "    }\n",
            "]\n",
            "\n",
            "--- Table Block 2 Preview (First 2 Rows) ---\n",
            "[\n",
            "    {\n",
            "        \"[10:02 AM] User: Yes\": \"q1_budget: \\\"$50\",\n",
            "        \"that's the one. Also\": \"000.00\\\"\"\n",
            "    },\n",
            "    {\n",
            "        \"[10:02 AM] User: Yes\": \"q2_budget: \\\"$45\",\n",
            "        \"that's the one. Also\": \"000.00\\\"\"\n",
            "    }\n",
            "]\n",
            "\n",
            "[INFO] Running natural language entity extraction...\n",
            "[INFO] File read successfully using encoding: utf-8\n",
            "\n",
            "--------------------------------------------------\n",
            "[REPORT] ENTITY EXTRACTION\n",
            "--------------------------------------------------\n",
            "Time Taken: 0.0082s\n",
            "Entities Found: 77\n",
            "{\n",
            "    \"Emails\": [\n",
            "        \"tech-support@msp-provider.net\",\n",
            "        \"sysadmin@tech-corp.io\",\n",
            "        \"30|INFO|auto_bot@cloud.aws\",\n",
            "        \"michael.s@paper-co.com\",\n",
            "        \"john.wick@continental-hotel.com\",\n",
            "        \"00|INFO|admin.sys@gateway.org\",\n",
            "        \"05|CRIT|sarah.connor@sky.net\",\n",
            "        \"15|CRIT|root_user@legacy-sys.net\",\n",
            "        \"doc.brown@future-tech.edu\",\n",
            "        \"22|WARN|vendor_access@supply-chain.com\",\n",
            "        \"sec-team@cyber-def.org\",\n",
            "        \"billing@continental-hotel.com\",\n",
            "        \"00|INFO|monitor_daemon@internal.net\",\n",
            "        \"12|WARN|j.doe_dev@startup.io\",\n",
            "        \"dwight.s@paper-co.com\"\n",
            "    ],\n",
            "    \"URLs\": [\n",
            "        \"www.\",\n",
            "        \"www.\",\n",
            "        \"www.\",\n",
            "        \"www.\"\n",
            "    ],\n",
            "    \"IPv4 Addresses\": [\n",
            "        \"192.168.1.100\",\n",
            "        \"10.0.0.0\",\n",
            "        \"10.5.2.1\",\n",
            "        \"10.0.0.55\",\n",
            "        \"192.168.45.12\",\n",
            "        \"192.168.100.50\",\n",
            "        \"172.16.254.1\"\n",
            "    ],\n",
            "    \"Phone Numbers\": [\n",
            "        \"800\",\n",
            "        \"555\"\n",
            "    ],\n",
            "    \"Dates\": [\n",
            "        \"2025-11-04\",\n",
            "        \"Dec 1st, 2025\",\n",
            "        \"Nov 28th, 2025\",\n",
            "        \"2025-11-01\",\n",
            "        \"Oct 31st, 2025\",\n",
            "        \"2025-10-15\",\n",
            "        \"2025-11-02\",\n",
            "        \"2025-11-03\",\n",
            "        \"2025-01-15\",\n",
            "        \"2025-11-28\",\n",
            "        \"2025-11-05\"\n",
            "    ],\n",
            "    \"Currency\": [\n",
            "        \"$500.00\",\n",
            "        \"$10,000.00\",\n",
            "        \"$299.99\",\n",
            "        \"$150.00\",\n",
            "        \"$4,500.00\",\n",
            "        \"$12.99\",\n",
            "        \"$0.15\",\n",
            "        \"$150.50\",\n",
            "        \"$2,100.00\",\n",
            "        \"$45.50\",\n",
            "        \"$4500.00\",\n",
            "        \"$12,500.75\",\n",
            "        \"$0.00\",\n",
            "        \"$5.00\",\n",
            "        \"$3,250.50\",\n",
            "        \"$75.00\",\n",
            "        \"$45,000.00\",\n",
            "        \"$600.00\",\n",
            "        \"$50,000.00\",\n",
            "        \"$1250.00\",\n",
            "        \"$9,999.99\"\n",
            "    ],\n",
            "    \"System Error Codes\": [\n",
            "        \"TXN-8824\",\n",
            "        \"555-0199\",\n",
            "        \"CRIT-999\",\n",
            "        \"TXN-8825\",\n",
            "        \"TXN-8822\",\n",
            "        \"WARN-404\",\n",
            "        \"TXN-8821\",\n",
            "        \"CVE-2025\",\n",
            "        \"AUTH-401\",\n",
            "        \"123-4567\",\n",
            "        \"TXN-8823\"\n",
            "    ],\n",
            "    \"Key-Value Pairs\": [\n",
            "        \"GENERATED\",\n",
            "        \"CC\",\n",
            "        \"NOTE\",\n",
            "        \"NOTE\",\n",
            "        \"Date\",\n",
            "        \"SEVERITY\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "==================================================\n",
            "[FINAL VERDICT] Accuracy Assessment: 100.00% (Exact Match Verified)\n",
            "==================================================\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MeG8gAWVlfh5",
        "outputId": "476af942-cc21-4154-d01d-7a0f492e68d3"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}