{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import json\n",
        "import hashlib\n",
        "import concurrent.futures\n",
        "import time\n",
        "from io import BytesIO\n",
        "\n",
        "# --- 1. Dependency Setup (Auto-Install) ---\n",
        "def install_dependencies():\n",
        "    print(\"System Check: Installing libraries...\")\n",
        "    packages = [\n",
        "        \"python-pptx\",\n",
        "        \"easyocr\",\n",
        "        \"pillow\",\n",
        "        \"pandas\",\n",
        "        \"numpy\",\n",
        "        \"opencv-python-headless\"\n",
        "    ]\n",
        "    for package in packages:\n",
        "        try:\n",
        "            __import__(package.replace(\"-\", \"_\").split(\"_\")[0])\n",
        "        except ImportError:\n",
        "            print(f\"   - Installing {package}...\")\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"])\n",
        "    print(\"Dependencies ready.\\n\")\n",
        "\n",
        "install_dependencies()\n",
        "\n",
        "import pptx\n",
        "from pptx.enum.shapes import MSO_SHAPE_TYPE\n",
        "from pptx.enum.dml import MSO_FILL_TYPE\n",
        "import easyocr\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# --- 2. Advanced Computer Vision Pipeline ---\n",
        "\n",
        "class ImageEnhancer:\n",
        "    \"\"\"\n",
        "    Handles complex image pre-processing using OpenCV to prepare inputs for OCR.\n",
        "    \"\"\"\n",
        "    @staticmethod\n",
        "    def process_image_variants(blob):\n",
        "        \"\"\"\n",
        "        Generates 3 versions of the image to ensure OCR doesn't miss anything.\n",
        "        Returns a list of numpy arrays.\n",
        "        \"\"\"\n",
        "        variants = []\n",
        "        try:\n",
        "            nparr = np.frombuffer(blob, np.uint8)\n",
        "            original = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "            if original is None: return []\n",
        "\n",
        "            # Variant 1: Grayscale + Denoised (Standard)\n",
        "            gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)\n",
        "            denoised = cv2.fastNlMeansDenoising(gray, h=10, templateWindowSize=7, searchWindowSize=21)\n",
        "            variants.append(denoised)\n",
        "\n",
        "            # Variant 2: CLAHE (Adaptive Contrast) - Good for bad lighting\n",
        "            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
        "            contrast = clahe.apply(gray)\n",
        "            variants.append(contrast)\n",
        "\n",
        "            # Variant 3: Otsu's Thresholding (Binarization) - Good for clear text separation\n",
        "            # Upscale first for small text\n",
        "            h, w = gray.shape\n",
        "            scale = 2 if w < 1000 else 1\n",
        "            if scale > 1:\n",
        "                resized = cv2.resize(gray, (w*scale, h*scale), interpolation=cv2.INTER_CUBIC)\n",
        "            else:\n",
        "                resized = gray\n",
        "            _, binary = cv2.threshold(resized, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "            variants.append(binary)\n",
        "\n",
        "        except Exception as e:\n",
        "            pass # Return whatever variants succeeded\n",
        "\n",
        "        return variants\n",
        "\n",
        "# --- 3. The OCR Engine (Parallel & Batched) ---\n",
        "\n",
        "class PowerOCREngine:\n",
        "    def __init__(self, use_gpu=True):\n",
        "        print(\"Loading Neural Network Models (EasyOCR)...\")\n",
        "        self.reader = easyocr.Reader(['en'], gpu=use_gpu) # Add 'fr', 'de', etc. here if needed\n",
        "        self.blob_cache = {} # Hash -> {text, conf}\n",
        "        self.queue = []      # List of {hash, variants, slide_idx}\n",
        "\n",
        "    def queue_image(self, blob, slide_idx):\n",
        "        if not blob: return\n",
        "\n",
        "        # Hash to avoid re-processing identical images (logos, footers)\n",
        "        img_hash = hashlib.md5(blob).hexdigest()\n",
        "\n",
        "        if img_hash not in self.blob_cache:\n",
        "            # We haven't seen this image yet. Add to queue.\n",
        "            # We don't store the blob directly, we store the tasks needed.\n",
        "            self.queue.append({\n",
        "                \"hash\": img_hash,\n",
        "                \"blob\": blob,\n",
        "                \"slide_idx\": slide_idx\n",
        "            })\n",
        "\n",
        "    def run_batch_process(self):\n",
        "        unique_tasks = {item[\"hash\"]: item[\"blob\"] for item in self.queue}\n",
        "        total_images = len(unique_tasks)\n",
        "\n",
        "        if total_images == 0:\n",
        "            return\n",
        "\n",
        "        print(f\"Starting Parallel OCR on {total_images} unique images...\")\n",
        "        print(\"   - Step 1: Generating Image Variants (Multi-Core CPU)...\")\n",
        "\n",
        "        # 1. Parallel Pre-processing\n",
        "        # Using ThreadPoolExecutor is effective here because OpenCV releases GIL for heavy ops\n",
        "        image_variants_map = {} # hash -> [variant1, variant2, variant3]\n",
        "\n",
        "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "            future_to_hash = {executor.submit(ImageEnhancer.process_image_variants, blob): h\n",
        "                              for h, blob in unique_tasks.items()}\n",
        "\n",
        "            for future in concurrent.futures.as_completed(future_to_hash):\n",
        "                h = future_to_hash[future]\n",
        "                try:\n",
        "                    variants = future.result()\n",
        "                    if variants:\n",
        "                        image_variants_map[h] = variants\n",
        "                except Exception as exc:\n",
        "                    print(f\"     Image error: {exc}\")\n",
        "\n",
        "        # 2. Batch OCR (GPU)\n",
        "        print(\"   - Step 2: Running Neural Networks (GPU Batching)...\")\n",
        "\n",
        "        # Flatten all variants into a single massive batch\n",
        "        # We need to track which variant belongs to which hash\n",
        "        batch_input = []\n",
        "        batch_mapping = [] # index -> hash\n",
        "\n",
        "        for h, variants in image_variants_map.items():\n",
        "            for v in variants:\n",
        "                batch_input.append(v)\n",
        "                batch_mapping.append(h)\n",
        "\n",
        "        if not batch_input:\n",
        "            return\n",
        "\n",
        "        # Run OCR in batches to respect VRAM\n",
        "        results = self.reader.readtext_batched(\n",
        "            batch_input,\n",
        "            detail=1, # Get confidence scores\n",
        "            batch_size=8, # Increase if you have a powerful GPU (A100), decrease for T4\n",
        "            paragraph=False # Must be False to retrieve confidence scores per word\n",
        "        )\n",
        "\n",
        "        # 3. Aggregation & Voting\n",
        "        print(\"   - Step 3: Aggregating & Selecting Best Results...\")\n",
        "\n",
        "        temp_results = {} # hash -> [(text, confidence), ...]\n",
        "\n",
        "        for i, result in enumerate(results):\n",
        "            # Result is a list of [bbox, text, conf]\n",
        "            # Since paragraph=False, we get detailed items\n",
        "\n",
        "            text_items = [item[1] for item in result]\n",
        "            conf_items = [item[2] for item in result]\n",
        "\n",
        "            if text_items:\n",
        "                text_found = \" \".join(text_items)\n",
        "                avg_conf = sum(conf_items) / len(conf_items) if conf_items else 0.0\n",
        "\n",
        "                if len(text_found) > 3: # Ignore noise\n",
        "                    h = batch_mapping[i]\n",
        "                    if h not in temp_results: temp_results[h] = []\n",
        "                    temp_results[h].append((text_found, avg_conf))\n",
        "\n",
        "        # Select the longest/most complete text from the variants for each hash\n",
        "        for h, candidates in temp_results.items():\n",
        "            # candidates is list of (text, conf)\n",
        "            # Heuristic: Select best extraction based on text length (usually implies more data captured)\n",
        "            best_candidate = max(candidates, key=lambda x: len(x[0]))\n",
        "\n",
        "            self.blob_cache[h] = {\n",
        "                \"text\": best_candidate[0],\n",
        "                \"conf\": best_candidate[1]\n",
        "            }\n",
        "\n",
        "# --- 4. The PPTX Parser ---\n",
        "\n",
        "class PresentationParser:\n",
        "    def __init__(self, file_path, ocr_engine):\n",
        "        self.file_path = file_path\n",
        "        self.ocr = ocr_engine\n",
        "        self.slides_data = []\n",
        "\n",
        "    def _extract_text_shape(self, shape):\n",
        "        \"\"\"Extracts editable text and tables.\"\"\"\n",
        "        items = []\n",
        "\n",
        "        # Text Frame\n",
        "        if shape.has_text_frame:\n",
        "            lines = [p.text.strip() for p in shape.text_frame.paragraphs if p.text.strip()]\n",
        "            if lines:\n",
        "                items.append({\"type\": \"text\", \"content\": \"\\n\".join(lines)})\n",
        "\n",
        "        # Table\n",
        "        if shape.has_table:\n",
        "            rows = []\n",
        "            for row in shape.table.rows:\n",
        "                cell_texts = [cell.text_frame.text.strip().replace(\"\\n\", \" \") for cell in row.cells]\n",
        "                if any(cell_texts): rows.append(cell_texts)\n",
        "            if rows:\n",
        "                items.append({\"type\": \"table\", \"content\": rows})\n",
        "\n",
        "        return items\n",
        "\n",
        "    def _find_images_recursive(self, shape, slide_idx):\n",
        "        \"\"\"Deep recursion to find images in Groups, Backgrounds, etc.\"\"\"\n",
        "        # 1. Direct Picture\n",
        "        if shape.shape_type == MSO_SHAPE_TYPE.PICTURE:\n",
        "            if hasattr(shape, \"image\"):\n",
        "                self.ocr.queue_image(shape.image.blob, slide_idx)\n",
        "\n",
        "        # 2. Shape with Picture Fill\n",
        "        elif shape.shape_type == MSO_SHAPE_TYPE.AUTO_SHAPE:\n",
        "            try:\n",
        "                if shape.fill.type == MSO_FILL_TYPE.PICTURE:\n",
        "                    self.ocr.queue_image(shape.fill.picture.image.blob, slide_idx)\n",
        "            except: pass\n",
        "\n",
        "        # 3. Groups\n",
        "        elif shape.shape_type == MSO_SHAPE_TYPE.GROUP:\n",
        "            for sub in shape.shapes:\n",
        "                self._find_images_recursive(sub, slide_idx)\n",
        "\n",
        "        # 4. Embedded OLE Objects (e.g., Excel/PDF preview images)\n",
        "        elif shape.shape_type == MSO_SHAPE_TYPE.EMBEDDED_OLE_OBJECT:\n",
        "             if hasattr(shape, \"image\"):\n",
        "                self.ocr.queue_image(shape.image.blob, slide_idx)\n",
        "\n",
        "    def parse(self):\n",
        "        if not os.path.exists(self.file_path):\n",
        "            return {\"error\": \"File not found\"}\n",
        "\n",
        "        print(f\"Parsing PPTX Structure: {self.file_path}\")\n",
        "        prs = pptx.Presentation(self.file_path)\n",
        "\n",
        "        total_slides = len(prs.slides)\n",
        "        print(f\"   - Found {total_slides} slides.\")\n",
        "\n",
        "        # Phase 1: Structure Extraction & Image Queuing\n",
        "        for i, slide in enumerate(prs.slides):\n",
        "            slide_obj = {\n",
        "                \"id\": i + 1,\n",
        "                \"content\": [],\n",
        "                \"notes\": \"\"\n",
        "            }\n",
        "\n",
        "            # Notes\n",
        "            if slide.has_notes_slide:\n",
        "                notes = slide.notes_slide.notes_text_frame.text.strip()\n",
        "                if notes: slide_obj[\"notes\"] = notes\n",
        "\n",
        "            # Shapes\n",
        "            for shape in slide.shapes:\n",
        "                # Get Text\n",
        "                slide_obj[\"content\"].extend(self._extract_text_shape(shape))\n",
        "                # Get Images (Queues them, doesn't process yet)\n",
        "                self._find_images_recursive(shape, i)\n",
        "\n",
        "            self.slides_data.append(slide_obj)\n",
        "\n",
        "        # Phase 2: Execute OCR\n",
        "        self.ocr.run_batch_process()\n",
        "\n",
        "        # Phase 3: Merge OCR Results\n",
        "        print(\"Merging OCR data back into structure...\")\n",
        "\n",
        "        # Create a lookup for images on each slide\n",
        "        # We need to match the original queue to the cache\n",
        "        for task in self.ocr.queue:\n",
        "            h = task[\"hash\"]\n",
        "            if h in self.ocr.blob_cache:\n",
        "                slide_idx = task[\"slide_idx\"]\n",
        "                cache_entry = self.ocr.blob_cache[h]\n",
        "                text = cache_entry[\"text\"]\n",
        "                conf = cache_entry[\"conf\"]\n",
        "\n",
        "                # Deduplication: Don't add if text is identical to something already extracted from shapes\n",
        "                is_duplicate = any(x['content'] == text for x in self.slides_data[slide_idx]['content'] if isinstance(x['content'], str))\n",
        "\n",
        "                if not is_duplicate:\n",
        "                    self.slides_data[slide_idx]['content'].append({\n",
        "                        \"type\": \"ocr_image\",\n",
        "                        \"content\": text,\n",
        "                        \"accuracy\": round(conf * 100, 2)\n",
        "                    })\n",
        "\n",
        "        return self.slides_data\n",
        "\n",
        "# --- 5. Main Execution ---\n",
        "\n",
        "def main():\n",
        "    # Colab File Upload Handler\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        print(\"Please upload your .pptx file:\")\n",
        "        uploaded = files.upload()\n",
        "        if not uploaded: return\n",
        "        filename = next(iter(uploaded))\n",
        "    except ImportError:\n",
        "        print(\"Not running in Colab. Using local file 'input.pptx' if available.\")\n",
        "        filename = \"input.pptx\" # Change this for local testing\n",
        "\n",
        "    if not os.path.exists(filename):\n",
        "        print(\"No file found to process.\")\n",
        "        return\n",
        "\n",
        "    # Initialize Engines\n",
        "    ocr_engine = PowerOCREngine(use_gpu=True)\n",
        "    parser = PresentationParser(filename, ocr_engine)\n",
        "\n",
        "    # Run\n",
        "    start_time = time.time()\n",
        "    result = parser.parse()\n",
        "    duration = time.time() - start_time\n",
        "\n",
        "    # Save\n",
        "    out_file = f\"{filename}_power_extract.json\"\n",
        "    with open(out_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(result, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"\\nCOMPLETED in {duration:.2f} seconds.\")\n",
        "    print(f\"Output saved to: {out_file}\")\n",
        "\n",
        "    # Preview\n",
        "    print(\"\\n--- JSON DATA PREVIEW (First 2 Slides) ---\")\n",
        "    print(json.dumps(result[:2], indent=2, ensure_ascii=False))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "System Check: Installing libraries...\n",
            "   - Installing python-pptx...\n",
            "   - Installing pillow...\n",
            "   - Installing opencv-python-headless...\n",
            "Dependencies ready.\n",
            "\n",
            "Please upload your .pptx file:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-df0dc0cf-6d36-45d6-9dd7-8135eef16780\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-df0dc0cf-6d36-45d6-9dd7-8135eef16780\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving EV-Charging-Infrastructure.pdf.pptx to EV-Charging-Infrastructure.pdf (3).pptx\n",
            "Loading Neural Network Models (EasyOCR)...\n",
            "Parsing PPTX Structure: EV-Charging-Infrastructure.pdf (3).pptx\n",
            "   - Found 10 slides.\n",
            "Merging OCR data back into structure...\n",
            "\n",
            "COMPLETED in 0.10 seconds.\n",
            "Output saved to: EV-Charging-Infrastructure.pdf (3).pptx_power_extract.json\n",
            "\n",
            "--- JSON DATA PREVIEW (First 2 Slides) ---\n",
            "[\n",
            "  {\n",
            "    \"id\": 1,\n",
            "    \"content\": [\n",
            "      {\n",
            "        \"type\": \"text\",\n",
            "        \"content\": \"EV Charging Infrastructure\\nBuilding India's Electric Future\\nComprehensive business model for scalable EV charging network\\ndeployment across Indian markets\"\n",
            "      }\n",
            "    ],\n",
            "    \"notes\": \"\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": 2,\n",
            "    \"content\": [\n",
            "      {\n",
            "        \"type\": \"text\",\n",
            "        \"content\": \"Our Product Portfolio\"\n",
            "      },\n",
            "      {\n",
            "        \"type\": \"text\",\n",
            "        \"content\": \"Fast DC Chargers\"\n",
            "      },\n",
            "      {\n",
            "        \"type\": \"text\",\n",
            "        \"content\": \"Smart Software Platform\"\n",
            "      },\n",
            "      {\n",
            "        \"type\": \"text\",\n",
            "        \"content\": \"Complete O&M Services\"\n",
            "      },\n",
            "      {\n",
            "        \"type\": \"text\",\n",
            "        \"content\": \"60kW to120kW ratingsfrom trusted Indian OEMs: Servotech, Exicom, and Mindra. Full compatibility with major EV models.\"\n",
            "      },\n",
            "      {\n",
            "        \"type\": \"text\",\n",
            "        \"content\": \"OCPP1.6compliant CMS with mobile app integration. Features include slot booking, payments, and AI-driven analytics.\"\n",
            "      },\n",
            "      {\n",
            "        \"type\": \"text\",\n",
            "        \"content\": \"Preventiveand corrective\"\n",
            "      },\n",
            "      {\n",
            "        \"type\": \"text\",\n",
            "        \"content\": \"maintenance with OEM partnerships. Insurance coverage and predictive maintenance alerts\\nincluded.\"\n",
            "      }\n",
            "    ],\n",
            "    \"notes\": \"\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fvqlGxTBFaz_",
        "outputId": "d21bec54-11d2-49a4-e427-da9bb10791f2"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}